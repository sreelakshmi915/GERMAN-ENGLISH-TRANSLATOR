{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zLpg39B9Kofz"
   },
   "outputs": [],
   "source": [
    "#Importing modules\n",
    "import string\n",
    "import re\n",
    "from numpy import array, argmax, random, take\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Embedding, RepeatVector\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import load_model\n",
    "from keras import optimizers\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "pd.set_option('display.max_colwidth', 200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SVrKgXJsLJWz"
   },
   "outputs": [],
   "source": [
    "#to read\n",
    "def read_data(filename):\n",
    "    file= open(filename,mode=\"rt\",encoding='UTF-8')#TO OPEN\n",
    "    text = file.read()\n",
    "    file.close()\n",
    "    return text\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OJMIyrN6LQTB"
   },
   "outputs": [],
   "source": [
    "def to_lines(text):\n",
    "      sents = text.strip().split('\\n') #formed sentences\n",
    "      sents = [i.split('\\t') for i in sents]\n",
    "      return sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h8HuBpxXLRM6",
    "outputId": "5b39b3a0-7db5-489f-b4d1-83e2cadf4a9b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Go.' 'Geh.']\n",
      " ['Hi.' 'Hallo!']\n",
      " ['Hi.' 'Grüß Gott!']\n",
      " ...\n",
      " ['Who else is in there?' 'Wer ist noch dort drin?']\n",
      " ['Who else was in here?' 'Wer war sonst noch hier drin?']\n",
      " ['Who fixed the window?' 'Wer hat das Fenster hergerichtet?']]\n"
     ]
    }
   ],
   "source": [
    "file = read_data(\"/content/drive/MyDrive/GERMAN_ENGLISH_TRANSLATOR/deu.txt\")\n",
    "ger_eng = to_lines(file)\n",
    "ger_eng=array(ger_eng)#converted to array\n",
    "\n",
    "ger_eng = ger_eng[:50000,:2]#we ned 1st 5000 rows\n",
    "print(ger_eng)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2-Un-62mLRb5"
   },
   "outputs": [],
   "source": [
    "#Text Pre-Processing\n",
    "#cleaning\n",
    "# Remove punctuation\n",
    "ger_eng[:,0] = [s.translate(str.maketrans('', '', string.punctuation)) for s in ger_eng[:,0]]\n",
    "ger_eng[:,1] = [s.translate(str.maketrans('', '', string.punctuation)) for s in ger_eng[:,1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0wirqhRkLRqC",
    "outputId": "e6660749-7009-4339-fe74-2833c29e9fd5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Go' 'Geh']\n",
      " ['Hi' 'Hallo']\n",
      " ['Hi' 'Grüß Gott']\n",
      " ...\n",
      " ['Who else is in there' 'Wer ist noch dort drin']\n",
      " ['Who else was in here' 'Wer war sonst noch hier drin']\n",
      " ['Who fixed the window' 'Wer hat das Fenster hergerichtet']]\n"
     ]
    }
   ],
   "source": [
    "print(ger_eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AGZNKGf4MCGy"
   },
   "outputs": [],
   "source": [
    "for i in range(len(ger_eng)):\n",
    "    ger_eng[i,0] = ger_eng[i,0].lower()\n",
    "    ger_eng[i,1] = ger_eng[i,1].lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V13oIIdVMJ5n"
   },
   "outputs": [],
   "source": [
    "# Text to Sequence Conversion\n",
    "\n",
    "\n",
    "ger=[]\n",
    "eng =[]\n",
    "for i in ger_eng[:,0]:\n",
    "      eng.append(len(i.split()))\n",
    "\n",
    "for i in ger_eng[:,1]:\n",
    "      ger.append(len(i.split()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "id": "EcQnSJnSMNt2",
    "outputId": "15ef86f9-922e-4965-e2c0-8da502fab9eb"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "length_df = pd.DataFrame({'eng':eng, 'ger':ger}) #converting to pd dataframe\n",
    "\n",
    "length_df.hist(bins = 30)#ploting histogram\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7elPLtjZMSKD"
   },
   "outputs": [],
   "source": [
    "# function to build a tokenizer\n",
    "def tokenization(lines):\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(lines)\n",
    "    return tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yxnYch4XMVN0"
   },
   "outputs": [],
   "source": [
    "# prepare english tokenizer\n",
    "eng_tokenizer = tokenization(ger_eng[:, 0])\n",
    "eng_vocab_size = len(eng_tokenizer.word_index) + 1\n",
    "eng_length = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iYAtsgPBMYdq"
   },
   "outputs": [],
   "source": [
    "#german tokenizer\n",
    "ger_tokenizer = tokenization(ger_eng[:,1])\n",
    "ger_vocab_size = len(ger_tokenizer.word_index)+1\n",
    "ger_length = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O4nw9mSAMcmG"
   },
   "outputs": [],
   "source": [
    "# encode and pad sequences\n",
    "def encode_sequences(tokenizer, length, lines):\n",
    "         # integer encode sequences\n",
    "         seq = tokenizer.texts_to_sequences(lines)\n",
    "         # pad sequences with 0 values\n",
    "         seq = pad_sequences(seq, maxlen=length, padding='post')\n",
    "         return seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "27vSnjUnMcxU"
   },
   "outputs": [],
   "source": [
    "#Model Building\n",
    "#We will now split the data into train and test set for model training and evaluation, respectively\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split data into train and test set\n",
    "train, test  = train_test_split(ger_eng, test_size=0.2, random_state = 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2pCGT_ffMc9C"
   },
   "outputs": [],
   "source": [
    "#We will encode German sentences as the input sequences and English sentences as the target sequences. \n",
    "# prepare training data\n",
    "X_train = encode_sequences(ger_tokenizer, ger_length, train[:, 1])\n",
    "Y_train = encode_sequences(eng_tokenizer, eng_length, train[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BNivWy9PMpD7"
   },
   "outputs": [],
   "source": [
    "# prepare validation data\n",
    "X_test = encode_sequences(ger_tokenizer, ger_length, test[:, 1])\n",
    "Y_test = encode_sequences(eng_tokenizer, eng_length, test[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uDy7TnnuMtls"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b1XNCA4yMtxZ"
   },
   "outputs": [],
   "source": [
    "# build NMT model\n",
    "def define_model(in_vocab,out_vocab, in_timesteps,out_timesteps,units):\n",
    "      model = Sequential()\n",
    "      model.add(Embedding(in_vocab, units, input_length=in_timesteps, mask_zero=True))\n",
    "      model.add(LSTM(units))\n",
    "      model.add(RepeatVector(out_timesteps))\n",
    "      model.add(LSTM(units, return_sequences=True))\n",
    "      model.add(Dense(out_vocab, activation='softmax'))\n",
    "      return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qh4B83paM1wv"
   },
   "outputs": [],
   "source": [
    "# model compilation\n",
    "model = define_model(ger_vocab_size, eng_vocab_size, ger_length, eng_length, 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G3_LhvTVM6jb",
    "outputId": "de24f11b-7646-4464-a645-d21f91eb23d9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
     ]
    }
   ],
   "source": [
    "rms = optimizers.RMSprop(lr=0.001)\n",
    "model.compile(optimizer=rms, loss='sparse_categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "omXJ1igzM_6-"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-n_93lEQM6w1",
    "outputId": "b65b0d1e-79bf-46c9-9469-5ca15d2af10f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "63/63 [==============================] - 29s 99ms/step - loss: 4.3165 - val_loss: 2.8071\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 2.80708, saving model to translation_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: translation_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: translation_model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "63/63 [==============================] - 5s 73ms/step - loss: 2.7173 - val_loss: 2.7058\n",
      "\n",
      "Epoch 00002: val_loss improved from 2.80708 to 2.70578, saving model to translation_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: translation_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: translation_model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/30\n",
      "63/63 [==============================] - 5s 72ms/step - loss: 2.5919 - val_loss: 2.5356\n",
      "\n",
      "Epoch 00003: val_loss improved from 2.70578 to 2.53559, saving model to translation_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: translation_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: translation_model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/30\n",
      "63/63 [==============================] - 5s 73ms/step - loss: 2.4224 - val_loss: 2.4049\n",
      "\n",
      "Epoch 00004: val_loss improved from 2.53559 to 2.40491, saving model to translation_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: translation_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: translation_model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/30\n",
      "63/63 [==============================] - 5s 74ms/step - loss: 2.2611 - val_loss: 2.2806\n",
      "\n",
      "Epoch 00005: val_loss improved from 2.40491 to 2.28056, saving model to translation_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: translation_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: translation_model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/30\n",
      "63/63 [==============================] - 5s 73ms/step - loss: 2.1140 - val_loss: 2.1633\n",
      "\n",
      "Epoch 00006: val_loss improved from 2.28056 to 2.16329, saving model to translation_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: translation_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: translation_model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/30\n",
      "63/63 [==============================] - 5s 74ms/step - loss: 1.9712 - val_loss: 2.0749\n",
      "\n",
      "Epoch 00007: val_loss improved from 2.16329 to 2.07490, saving model to translation_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: translation_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: translation_model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/30\n",
      "63/63 [==============================] - 5s 73ms/step - loss: 1.8587 - val_loss: 1.9860\n",
      "\n",
      "Epoch 00008: val_loss improved from 2.07490 to 1.98601, saving model to translation_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: translation_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: translation_model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/30\n",
      "63/63 [==============================] - 5s 74ms/step - loss: 1.7426 - val_loss: 1.9220\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.98601 to 1.92201, saving model to translation_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: translation_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: translation_model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/30\n",
      "63/63 [==============================] - 5s 75ms/step - loss: 1.6422 - val_loss: 1.8351\n",
      "\n",
      "Epoch 00010: val_loss improved from 1.92201 to 1.83510, saving model to translation_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: translation_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: translation_model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/30\n",
      "63/63 [==============================] - 5s 75ms/step - loss: 1.5385 - val_loss: 1.7621\n",
      "\n",
      "Epoch 00011: val_loss improved from 1.83510 to 1.76211, saving model to translation_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: translation_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: translation_model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/30\n",
      "63/63 [==============================] - 5s 75ms/step - loss: 1.4472 - val_loss: 1.7028\n",
      "\n",
      "Epoch 00012: val_loss improved from 1.76211 to 1.70285, saving model to translation_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: translation_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: translation_model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/30\n",
      "63/63 [==============================] - 5s 75ms/step - loss: 1.3521 - val_loss: 1.6752\n",
      "\n",
      "Epoch 00013: val_loss improved from 1.70285 to 1.67519, saving model to translation_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: translation_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: translation_model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/30\n",
      "63/63 [==============================] - 5s 75ms/step - loss: 1.2646 - val_loss: 1.6039\n",
      "\n",
      "Epoch 00014: val_loss improved from 1.67519 to 1.60389, saving model to translation_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: translation_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: translation_model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/30\n",
      "63/63 [==============================] - 5s 76ms/step - loss: 1.1863 - val_loss: 1.5802\n",
      "\n",
      "Epoch 00015: val_loss improved from 1.60389 to 1.58021, saving model to translation_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: translation_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: translation_model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/30\n",
      "63/63 [==============================] - 5s 76ms/step - loss: 1.1050 - val_loss: 1.5294\n",
      "\n",
      "Epoch 00016: val_loss improved from 1.58021 to 1.52939, saving model to translation_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: translation_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: translation_model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/30\n",
      "63/63 [==============================] - 5s 76ms/step - loss: 1.0266 - val_loss: 1.4812\n",
      "\n",
      "Epoch 00017: val_loss improved from 1.52939 to 1.48125, saving model to translation_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: translation_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: translation_model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/30\n",
      "63/63 [==============================] - 5s 77ms/step - loss: 0.9599 - val_loss: 1.4437\n",
      "\n",
      "Epoch 00018: val_loss improved from 1.48125 to 1.44372, saving model to translation_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: translation_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: translation_model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/30\n",
      "63/63 [==============================] - 5s 76ms/step - loss: 0.8858 - val_loss: 1.4232\n",
      "\n",
      "Epoch 00019: val_loss improved from 1.44372 to 1.42317, saving model to translation_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: translation_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: translation_model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/30\n",
      "63/63 [==============================] - 5s 76ms/step - loss: 0.8268 - val_loss: 1.3879\n",
      "\n",
      "Epoch 00020: val_loss improved from 1.42317 to 1.38787, saving model to translation_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: translation_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: translation_model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/30\n",
      "63/63 [==============================] - 5s 76ms/step - loss: 0.7676 - val_loss: 1.3777\n",
      "\n",
      "Epoch 00021: val_loss improved from 1.38787 to 1.37773, saving model to translation_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: translation_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: translation_model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/30\n",
      "63/63 [==============================] - 5s 76ms/step - loss: 0.7123 - val_loss: 1.3519\n",
      "\n",
      "Epoch 00022: val_loss improved from 1.37773 to 1.35188, saving model to translation_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: translation_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: translation_model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/30\n",
      "63/63 [==============================] - 5s 76ms/step - loss: 0.6523 - val_loss: 1.3254\n",
      "\n",
      "Epoch 00023: val_loss improved from 1.35188 to 1.32545, saving model to translation_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: translation_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: translation_model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/30\n",
      "63/63 [==============================] - 5s 76ms/step - loss: 0.6030 - val_loss: 1.3108\n",
      "\n",
      "Epoch 00024: val_loss improved from 1.32545 to 1.31084, saving model to translation_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: translation_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: translation_model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/30\n",
      "63/63 [==============================] - 5s 75ms/step - loss: 0.5524 - val_loss: 1.3036\n",
      "\n",
      "Epoch 00025: val_loss improved from 1.31084 to 1.30356, saving model to translation_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: translation_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: translation_model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/30\n",
      "63/63 [==============================] - 5s 76ms/step - loss: 0.5065 - val_loss: 1.2931\n",
      "\n",
      "Epoch 00026: val_loss improved from 1.30356 to 1.29307, saving model to translation_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: translation_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: translation_model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/30\n",
      "63/63 [==============================] - 5s 76ms/step - loss: 0.4661 - val_loss: 1.3069\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 1.29307\n",
      "Epoch 28/30\n",
      "63/63 [==============================] - 5s 76ms/step - loss: 0.4291 - val_loss: 1.2760\n",
      "\n",
      "Epoch 00028: val_loss improved from 1.29307 to 1.27604, saving model to translation_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: translation_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: translation_model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/30\n",
      "63/63 [==============================] - 5s 77ms/step - loss: 0.3965 - val_loss: 1.2678\n",
      "\n",
      "Epoch 00029: val_loss improved from 1.27604 to 1.26779, saving model to translation_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: translation_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: translation_model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/30\n",
      "63/63 [==============================] - 5s 76ms/step - loss: 0.3570 - val_loss: 1.2690\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 1.26779\n"
     ]
    }
   ],
   "source": [
    "filename = 'translation_model'\n",
    "checkpoint = ModelCheckpoint(filename, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "# train model\n",
    "history = model.fit(X_train, Y_train.reshape(Y_train.shape[0], Y_train.shape[1], 1),\n",
    "                    epochs=30, batch_size=512, validation_split = 0.2,callbacks=[checkpoint], \n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "id": "dYmEZlr0PLcT",
    "outputId": "ea69e305-6e59-4868-a368-59024a054862"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.legend(['train','validation'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZGMIfxxQPM02",
    "outputId": "a4e6fbb2-a567-4961-996c-68526f63bc34"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    }
   ],
   "source": [
    "#LOAD MODEL\n",
    "model = load_model('translation_model')\n",
    "preds = model.predict_classes(X_test.reshape((X_test.shape[0],X_test.shape[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W7RHXl67PQH1"
   },
   "outputs": [],
   "source": [
    "def get_word(n, tokenizer):\n",
    "      for word, index in tokenizer.word_index.items():\n",
    "          if index == n:\n",
    "              return word\n",
    "      return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GDmSAliAPcUs"
   },
   "outputs": [],
   "source": [
    "#Convert predictions into text (English):\n",
    "preds_text = []\n",
    "for i in preds:\n",
    "    temp = []\n",
    "    for j in range(len(i)):\n",
    "        t = get_word(i[j], eng_tokenizer)\n",
    "        if j > 0:\n",
    "            if (t == get_word(i[j-1], eng_tokenizer)) or (t == None):\n",
    "                    temp.append('')\n",
    "            else:\n",
    "                    temp.append(t)\n",
    "        else:\n",
    "                if(t == None):\n",
    "                        temp.append('')\n",
    "                else:\n",
    "                        temp.append(t) \n",
    "\n",
    "    preds_text.append(' '.join(temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pxQLpenfPf2I"
   },
   "outputs": [],
   "source": [
    "#Let’s put the original English sentences in the test dataset and the predicted sentences in a dataframe:\n",
    "pred_df = pd.DataFrame({'actual' : test[:,0], 'predicted' : preds_text})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1xIolrErSXrS"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 509
    },
    "id": "ZA438ZC4Pg50",
    "outputId": "281ce0a4-f8d5-48f5-8202-774ca0a78eb1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6375</th>\n",
       "      <td>what did tom want</td>\n",
       "      <td>what did tom want</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3296</th>\n",
       "      <td>im listening to you</td>\n",
       "      <td>im hear you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>824</th>\n",
       "      <td>youre very modest</td>\n",
       "      <td>youre very humble</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1484</th>\n",
       "      <td>it was too late</td>\n",
       "      <td>it was too</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9484</th>\n",
       "      <td>this is really bad</td>\n",
       "      <td>this is bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5036</th>\n",
       "      <td>tom was very sick</td>\n",
       "      <td>tom was really ill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5821</th>\n",
       "      <td>she has short hair</td>\n",
       "      <td>she has long hair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5360</th>\n",
       "      <td>where did i put it</td>\n",
       "      <td>where did i get it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9354</th>\n",
       "      <td>its balmy today</td>\n",
       "      <td>its is today</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4889</th>\n",
       "      <td>i cant leave tom</td>\n",
       "      <td>i cant let tom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3650</th>\n",
       "      <td>theyll be pleased</td>\n",
       "      <td>theyll be like</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6258</th>\n",
       "      <td>its cold today</td>\n",
       "      <td>its very cold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>525</th>\n",
       "      <td>i have 13 cats</td>\n",
       "      <td>i have thirteen cats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2058</th>\n",
       "      <td>can i go to work</td>\n",
       "      <td>can i go to bed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2145</th>\n",
       "      <td>i dont want it</td>\n",
       "      <td>i dont want it</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   actual                 predicted\n",
       "6375    what did tom want     what did tom want    \n",
       "3296  im listening to you          im hear you     \n",
       "824     youre very modest    youre very humble     \n",
       "1484      it was too late           it was too     \n",
       "9484   this is really bad          this is bad     \n",
       "5036    tom was very sick    tom was really ill    \n",
       "5821   she has short hair     she has long hair    \n",
       "5360   where did i put it     where did i get it   \n",
       "9354      its balmy today         its is today     \n",
       "4889     i cant leave tom        i cant let tom    \n",
       "3650    theyll be pleased       theyll be like     \n",
       "6258       its cold today        its very cold     \n",
       "525        i have 13 cats  i have thirteen cats    \n",
       "2058     can i go to work        can i go to bed   \n",
       "2145       i dont want it        i dont want it    "
      ]
     },
     "execution_count": 34,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print 15 rows randomly\n",
    "pred_df.sample(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IO078bnXSvWP"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "GERMAN_ENGLISH_TRANSLATOR.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
